{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# World University Analysis (2023)\nI greet everyone in another work where we will use a dataset containing data on many universities in the world to examine universities in Russia and the world as a whole to understand where, possibly, it is worth going to study if you suddenly want to purposefully learn something new in different countries and fields in general.\n\nI already took the data from a ready-made table collected during the analysis in 2023 from the Kaggle.com website.\nYou can view and download the data via the link: https://www.kaggle.com/datasets/tariqbashir/world-university-ranking-2023\n\n---\n## Dataset Description\n```\nWorld University Rankings 2023 is based upon 1,799 universities across 104 countries and regions based on many (at least 13) performance indicators that measure teaching, research, knowledge transfer, and international outlook. Data was collected from over 2,500 institutions, including survey responses from 40,000 scholars and analysis of over 121 million citations in 15.5 million research publications. The US has the most institutions overall and in the top 200, but China has overtaken Australia for the fourth-highest number of institutions in the top 200. The University of Oxford is ranked first for this year, while the highest new entry is Italy's Humanitas University.\n```\n\n---\n\nComment: Judging from the data, even after processing all the values and bringing them to a normal form, more than 2000 (to be exact, 2345 rows) universities are obtained, so the phrase \"based upon 1,799 universities\" makes me wonder where I am wrong in my calculations.\n## Import necessary Python libraries\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"db=pd.read_csv('dataset.csv',encoding='ISO-8859-1') # Without this encoding parameter, a file reading error will occur.\ndb","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset Comment\nJust look at this madness! NaN rows, different parameters in one column, everything needs to be normalized urgently.\n\n---\n## Table normalization","metadata":{}},{"cell_type":"code","source":"db.drop(labels=0, inplace=True)\ndb.reset_index(inplace=True, drop=True)\ndef find_irregularity(db,full=False):\n    ''' \n    Let's check if the entire table has this structure or if it is heterogeneous.\n    '''\n    prev=-1\n    sum=0\n    for index, row in db.iterrows():\n        # print(index,row['Rank'])\n        if pd.isna(row['Rank']):\n            if index-prev!=2:\n                sum+=1\n                if sum<3 or full==True: #To avoid cluttering the output, I set a limit on the output: sum<10.\n                    print('-------------------------')\n                    print(f'Attention, there is heterogeneity in the data.')\n                    for i in range(index-2,index+3):\n                        print(i,db['Rank'].iloc[i],db['Name'].iloc[i], index-prev)\n            prev=index\n    print(f\"---------------------\\nNumber of heterogeneities:{sum}\")\n    if sum==0:\n        print(f\"Congrats, all clear!\")\nfind_irregularity(db)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Conclusion:\nAs you can see, there is heterogeneity in the data. Besides the fact that one column contains both the names of universities and their countries, there is also a certain Explore row that changes the sequence, not allowing me to correctly and quickly convert the table without breaking its structure.\nIf you carefully study the table, you can assume that we do not need the Explore rows at all, they do not give us anything at all. Let's remove them from here.","metadata":{}},{"cell_type":"code","source":"db=db[db['Name']!='Explore']\ndb.reset_index(inplace=True, drop=True)\nfind_irregularity(db, full=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As you can see, there is only one heterogeneity left, and it is very strange. Let's take a closer look at it.","metadata":{}},{"cell_type":"code","source":"db.iloc[2345:2351]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As you can see, there is essentially an empty row with no data written because the university is most likely not accredited.\n> Unaccredited Universities is a list of colleges, universities, and other institutions that do not have the equivalent of regional academic accreditation. Some of these institutions may have legal authority to enroll students and grant degrees, but do not have regional academic accreditation for various reasons.\n\nYou can find unaccredited universities using this link: https://www.scholaro.com/unaccredited-universities/\n\nIn our case, we will simply remove all such rows if they exist (there seems to be only one).","metadata":{}},{"cell_type":"code","source":"db=db[db['Name']!='Not accredited']\ndb.reset_index(inplace=True, drop=True)\nfind_irregularity(db, full=True) ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"countries=[]\nindexes=[]\nfor index, row in db.iterrows():\n    if index%2==1:\n        countries.append(row['Name'])\n        indexes.append(index)\ndb.drop(labels=indexes, inplace=True)\ndb.reset_index(inplace=True, drop=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"db.insert(2,'Country',countries)\ndb","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n## Errors in the text\n\nYou may have already noticed that some values look a bit strange. Let me list for you what cannot satisfy us in the data:\n\n1. Data from columns, for example, No. of FTE Students, are written with a comma instead of a period, so the numbers are not recognized as numbers. Let's make sure of this by checking the data type of all values.","metadata":{}},{"cell_type":"code","source":"db.dtypes","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As you can see, only the 'No. of students per staff' column has no problems (so far). Let's change the data, bringing it to a normal view!\n\nP.S. In fact, the person who collected these data in this form should have his hands cut off. It would be possible to run them through Power Query to avoid problems with processing.\n\n","metadata":{}}]}